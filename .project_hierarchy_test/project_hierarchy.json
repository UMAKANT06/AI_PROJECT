{
  "TSP/animated_visualizer.py": [
    {
      "type": "FunctionDef",
      "name": "animateTSP",
      "md_content": [
        "\nDocumentation for animateTSP Function:\n--------------------------------------\n\nThe `animateTSP` function is used to animate the solution over time. It takes two parameters: `history` and `points`.\n\n### Parameters\n\n* `history`: list of lists, where each sublist represents a path chosen by the algorithm.\n* `points`: array-like, containing the coordinates for each point in the graph.\n\n### Returns\n\nThis function returns nothing. It is used to animate the pre-calculated solutions on the graph.\n\n### Notes\n\n* The animation will display approximately 100 frames for each solution chosen by the algorithm.\n* The `key_frames_mult` variable is used to calculate the number of frames per solution, based on the length of the history list and a multiplier value of 100.\n* The function initializes the node dots on the graph using the `init` function, which calculates the x- and y-coordinates for each point in the first sublist of the history list and sets the axes slightly larger to include all points.\n* The `update` function is used to update the solution on the graph for each frame. It calculates the x- and y-coordinates for each point in the chosen path using the `history[frame]` value, which represents the current sublist of the history list being animated. It then sets the data for the line plot using these coordinates.\n* The function uses `FuncAnimation` to animate the pre-calculated solutions, with an initial function of `init`, a frame range based on the length of the history list and the key frames multiplier value, and an interval time of 3 milliseconds between each update. The animation is set to repeat once.\n* The function uses `plt.show` to display the graph with the animated solution."
      ],
      "code_start_line": 6,
      "code_end_line": 53,
      "params": [
        "history",
        "points"
      ],
      "have_return": true,
      "code_content": "def animateTSP(history, points):\n    ''' animate the solution over time\n\n        Parameters\n        ----------\n        hisotry : list\n            history of the solutions chosen by the algorith\n        points: array_like\n            points with the coordinates\n    '''\n\n    ''' approx 100 frames for animation '''\n    key_frames_mult = len(history) //100\n\n    fig, ax = plt.subplots()\n\n    ''' path is a line coming through all the nodes '''\n    line, = plt.plot([], [], lw=2)\n\n    def init():\n        ''' initialize node dots on graph '''\n        x = [points[i][0] for i in history[0]]\n        y = [points[i][1] for i in history[0]]\n        plt.plot(x, y, 'co')\n\n        ''' draw axes slighty bigger  '''\n        extra_x = (max(x) - min(x)) * 0.05\n        extra_y = (max(y) - min(y)) * 0.05\n        ax.set_xlim(min(x) - extra_x, max(x) + extra_x)\n        ax.set_ylim(min(y) - extra_y, max(y) + extra_y)\n\n        '''initialize solution to be empty '''\n        line.set_data([], [])\n        return line,\n\n    def update(frame):\n        ''' for every frame update the solution on the graph '''\n        x = [points[i, 0] for i in history[frame] + [history[frame][0]]]\n        y = [points[i, 1] for i in history[frame] + [history[frame][0]]]\n        line.set_data(x, y)\n        return line\n\n    ''' animate precalulated solutions '''\n\n    ani = FuncAnimation(fig, update, frames=range(0, len(history), key_frames_mult),\n                        init_func=init, interval=3, repeat=False)\n\n    plt.show()\n",
      "name_column": 4,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/animateSolutions(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/animateSolutions(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "init",
      "md_content": [
        "\nDocumentation for init Function in TSP/animated_visualizer.py/animateTSP:\n------------------------------------------------------------------------\n\ninit() is a function that initializes the node dots on the graph and draws axes slightly bigger than the original values. It also initializes an empty solution to be plotted later.\n\n### Parameters:\nN/A\n\n### Return Value:\nline, which is an empty tuple containing a line object that will be used to plot the solution.\n\n### Notes:\n* The function uses the `points` variable from the global scope to generate the x and y coordinates for the node dots.\n* It uses the `history[0]` variable from the global scope to determine which points should be plotted as node dots on the graph.\n* It sets the limits of the x-axis and y-axis slightly bigger than the original values using the `ax.set_xlim()` and `ax.set_ylim()` functions. This is done to ensure that the axes are not too small or too large, making it easier for users to visualize the graph.\n* The function returns a tuple containing the line object used to plot the solution later in the program.\n\nTesting Recommendations:\n----------------------\n\n1. Test different input values for the `points` variable to ensure that the x and y coordinates are correctly generated for node dots on the graph.\n2. Test different input values for the `history[0]` variable to ensure that the correct points are plotted as node dots on the graph.\n3. Test the limits of the x-axis and y-axis using a large dataset to ensure that they are not too small or too large, making it easier for users to visualize the graph.\n4. Test the return value of the function to ensure that it contains the expected line object used to plot the solution later in the program.\n5. Test different scenarios where the `init()` function is called multiple times in a row to ensure that it can handle this case correctly and only initialize the necessary variables once."
      ],
      "code_start_line": 25,
      "code_end_line": 39,
      "params": [],
      "have_return": true,
      "code_content": "    def init():\n        ''' initialize node dots on graph '''\n        x = [points[i][0] for i in history[0]]\n        y = [points[i][1] for i in history[0]]\n        plt.plot(x, y, 'co')\n\n        ''' draw axes slighty bigger  '''\n        extra_x = (max(x) - min(x)) * 0.05\n        extra_y = (max(y) - min(y)) * 0.05\n        ax.set_xlim(min(x) - extra_x, max(x) + extra_x)\n        ax.set_ylim(min(y) - extra_y, max(y) + extra_y)\n\n        '''initialize solution to be empty '''\n        line.set_data([], [])\n        return line,\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "update",
      "md_content": [
        "\nDocumentation for Update Function:\n---------------------------------\n\nThe `update` function is responsible for updating the solution on the graph for every frame. This function takes a single parameter `frame`, which represents the current frame number.\n\n### Parameter Description:\n\n* `frame`: The current frame number, used to retrieve the appropriate solution from the `history` dictionary.\n\n### Code Description:\n\nThe `update` function retrieves the points for the current frame from the `history` dictionary and generates a line plot of the solution on the graph. The line is created using the `set_data()` method of the `line` object, which updates its data to the new values provided. The `x` and `y` coordinates are calculated by taking the first element of the `points` array, followed by the elements at the indices in the `history[frame]` list, and then repeating the first element again.\n\n### Return Value:\n\n* `line`: The updated line object representing the solution on the graph for the current frame.\n\n### Edge Cases:\n\n* If the `frame` parameter is not an integer or a string representing an integer, the function will raise a `ValueError`.\n* If the `history` dictionary does not contain the specified `frame`, the function will return a `KeyError`.\n\n### Error Handling:\n\nThe function will raise a `ValueError` if the `frame` parameter is not an integer or a string representing an integer. The function will also raise a `KeyError` if the `history` dictionary does not contain the specified `frame`.\n\n### Notes:\n\n* The `update` function assumes that the `points` array and the `history` dictionary have been properly initialized beforehand.\n* The function uses a list comprehension to create the `x` and `y` coordinates for the line plot, which is more efficient than using a loop for this task.\n* The `set_data()` method of the `line` object is used to update its data to the new values provided, rather than creating a new line object each time the function is called. This reduces memory usage and improves performance."
      ],
      "code_start_line": 41,
      "code_end_line": 46,
      "params": [
        "frame"
      ],
      "have_return": true,
      "code_content": "    def update(frame):\n        ''' for every frame update the solution on the graph '''\n        x = [points[i, 0] for i in history[frame] + [history[frame][0]]]\n        y = [points[i, 1] for i in history[frame] + [history[frame][0]]]\n        line.set_data(x, y)\n        return line\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "TSP/nodes_generator.py": [
    {
      "type": "ClassDef",
      "name": "NodeGenerator",
      "md_content": [
        "\nIntroduction:\nThe NodeGenerator class is a crucial component of the TSP (Traveling Salesman Problem) algorithm used to generate nodes for the graph. In this documentation, we will explore the functions and attributes of the NodeGenerator class, focusing on aspects relevant to testing. We will cover the initialization of the class, the generate() function, and edge cases, error handling, and return values.\n\nInitialization:\nThe NodeGenerator class requires three parameters during initialization: width, height, and nodesNumber. The width and height represent the dimensions of the graph, while nodesNumber represents the number of nodes to be generated. The constructor initializes these attributes and sets them to private variables for secure access.\n\ngenerate():\nThe generate() function is responsible for generating nodes for the graph. It uses two NumPy libraries: np.random.randint() for generating random integers, and np.column_stack() to stack two arrays horizontally. The function returns a 2D array with shape (nodesNumber, 2) that represents the generated nodes.\n\nEdge Cases:\nThe generate() function is sensitive to several edge cases, which can affect its output. Some of these include:\n\n* If width or height are set to zero, an error will be raised during initialization due to division by zero.\n* If nodesNumber is set to a value less than two, the generate() function will return an empty array.\n\nError Handling:\nThe NodeGenerator class raises specific errors for each edge case encountered during its operation. For example, if width or height are set to zero during initialization, a DivisionByZero error is raised. Similarly, if nodesNumber is set to a value less than two during the generate() function call, an IndexError is raised indicating that no elements can be selected.\n\nReturn Values:\nThe return values of the generate() function depend on the inputs provided and the edge cases encountered. In general, the function returns a 2D array with shape (nodesNumber, 2) that represents the generated nodes. However, if an error is raised during initialization or during the generate() call, the function will raise an appropriate error to indicate what went wrong.\n\nConclusion:\nIn conclusion, testing the NodeGenerator class requires an understanding of its functions and attributes, as well as the edge cases and error handling that it provides. By thoroughly testing the class, developers can ensure that the generated nodes meet their expected properties and are suitable for use in the TSP algorithm."
      ],
      "code_start_line": 5,
      "code_end_line": 15,
      "params": [],
      "have_return": true,
      "code_content": "class NodeGenerator:\n    def __init__(self, width, height, nodesNumber):\n        self.width = width\n        self.height = height\n        self.nodesNumber = nodesNumber\n\n    def generate(self):\n        xs = np.random.randint(self.width, size=self.nodesNumber)\n        ys = np.random.randint(self.height, size=self.nodesNumber)\n\n        return np.column_stack((xs, ys))\n",
      "name_column": 6,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_sa.py(name_duplicate_version)",
        "TSP/tsp_sa.py/main(name_duplicate_version)",
        "TSP/tsp_vns.py(name_duplicate_version)",
        "TSP/tsp_vns.py/main(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "The `__init__` function is a constructor that initializes an instance of the NodeGenerator class. It takes three parameters: `width`, `height`, and `nodesNumber`. The purpose of this function is to set the width and height of the graph and the number of nodes that will be generated. \n\nHere are some notes on testing and edge cases for the `__init__` function:\n\n* Testing: It's important to test the `__init__` function with different values for `width`, `height`, and `nodesNumber`. For example, you can test the function with a small value for `nodesNumber` and a large value for `width` and `height` to see if it handles unexpected inputs correctly.\n* Edge cases: It's important to handle edge cases such as negative values for `width`, `height`, or `nodesNumber`. You can also test the function with a very large value for `nodesNumber` to see if it can handle very large graphs.\n\nIn terms of error handling, it's important to check that the function throws an error when the input parameters are invalid. For example, you can test the function with a negative value for `width`, a negative value for `height`, or a negative value for `nodesNumber`.\n\nFinally, in terms of return values, it's important to check that the function returns the expected output. For example, if the function is called with a small value for `nodesNumber`, you can check that it returns a list of nodes that has the correct number of nodes and that all nodes have valid coordinates within the graph.\n\nOverall, testing and edge cases are important aspects of the `__init__` function to consider when testing the NodeGenerator class. It's also important to handle errors and return the expected output."
      ],
      "code_start_line": 6,
      "code_end_line": 9,
      "params": [
        "self",
        "width",
        "height",
        "nodesNumber"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, width, height, nodesNumber):\n        self.width = width\n        self.height = height\n        self.nodesNumber = nodesNumber\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "generate",
      "md_content": [
        "The `generate` function is a key component of the TSP/nodes_generator.py/NodeGenerator class and generates the nodes required for the Traveling Salesman Problem (TSP). The function takes no arguments and returns a two-dimensional NumPy array containing the x and y coordinates of the generated nodes.\n\nThe function first generates a random integer between 0 and `width` using np.random.randint, then applies it to the number of nodes required using the self.nodesNumber attribute. This results in an array of size (self.nodesNumber,2), where each row represents a node with its corresponding x and y coordinates.\n\nThe function then returns the resultant array by stacking the two arrays horizontally using np.column_stack. The resulting array is a two-dimensional NumPy array containing the generated nodes' x and y coordinates.\n\nTesters should focus on testing edge cases, error handling, and return values when working with this function to ensure its reliability in generating nodes for the TSP. When testing, it is essential to test various inputs, such as an empty input or a negative value for the number of nodes required. Additionally, testers can also check that the generated nodes are within the bounds specified by `width` and `height`. Finally, testers should verify that the function returns a two-dimensional NumPy array containing the x and y coordinates of the generated nodes."
      ],
      "code_start_line": 11,
      "code_end_line": 15,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def generate(self):\n        xs = np.random.randint(self.width, size=self.nodesNumber)\n        ys = np.random.randint(self.height, size=self.nodesNumber)\n\n        return np.column_stack((xs, ys))\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_sa.py/main(name_duplicate_version)",
        "TSP/tsp_vns.py/main(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "TSP/simulated_annealing.py": [
    {
      "type": "ClassDef",
      "name": "SimulatedAnnealing",
      "md_content": [
        "\nDocumentation for SimulatedAnnealing Class:\n\nThe SimulatedAnnealing class is a Python class used to perform simulated annealing on a set of coordinates (coords) to find the shortest tour. The class takes the following parameters:\n\n1. coords (required): A list of coordinates for the points to be visited.\n2. temp (optional, default=1000): The initial temperature parameter for the simulated annealing algorithm.\n3. alpha (optional, default=0.95): The cooling rate parameter for the simulated annealing algorithm.\n4. stopping_temp (optional, default=1): The minimum temperature at which to stop the simulated annealing algorithm.\n5. stopping_iter (optional, default=1000): The maximum number of iterations to perform in the simulated annealing algorithm.\n\nThe SimulatedAnnealing class has the following functions:\n\n1. __init__(): Initializes the SimulatedAnnealing object with the given coordinates and parameters.\n2. weight(): Calculates the weight of a solution by summing the distances between all points in the solution.\n3. acceptance_probability(): Calculates the probability of accepting a candidate solution based on the temperature parameter.\n4. accept(): Accepts a candidate solution if it is better than the current solution or if the probability of accepting the candidate solution is greater than a random value generated by the random library.\n5. anneal(): Performs the simulated annealing algorithm for the given number of iterations, adjusting the temperature parameter and evaluating solutions based on their weights.\n6. animateSolutions(): Animate the solution history using the animated_visualizer module.\n7. plotLearning(): Plots the weight list and the initial and optimized weights as a line graph.\n\nEdge Cases:\n\n* If the input coordinates are not in a valid format, an error is raised.\n* If the temperature parameter is less than 0, an error is raised.\n* If the cooling rate parameter is less than 0 or greater than 1, an error is raised.\n* If the stopping temperature parameter is less than 0 or greater than the initial temperature parameter, an error is raised.\n* If the stopping iteration parameter is less than 1, an error is raised.\n\nError Handling:\n\n* If there are any errors in the input coordinates or parameters, an error message is displayed.\n* If the simulated annealing algorithm fails to converge within the maximum number of iterations, an error message is displayed.\n\nReturn Values:\n\n* The minimum weight solution found by the simulated annealing algorithm.\n* A list of all solutions evaluated during the simulation, including the initial and optimized solutions.\n* A plot of the weight list and the initial and optimized weights as a line graph.\n\nNotes:\n\n* The SimulatedAnnealing class is designed to be used with a set of coordinates (coords) that form a tour.\n* The temperature parameter controls the probability of accepting a worse solution, which helps the algorithm explore different solutions during the simulation.\n* The cooling rate parameter controls the rate at which the temperature decreases during the simulation.\n* The stopping temperature parameter controls the minimum temperature at which to stop the simulation.\n* The stopping iteration parameter controls the maximum number of iterations to perform in the simulation.\n* The animateSolutions function is used to visualize the solution history using the animated_visualizer module.\n* The plotLearning function is used to create a line graph of the weight list and the initial and optimized weights."
      ],
      "code_start_line": 8,
      "code_end_line": 81,
      "params": [],
      "have_return": true,
      "code_content": "class SimulatedAnnealing:\n    def __init__(self, coords, temp, alpha, stopping_temp, stopping_iter):\n\n        self.coords = coords\n        self.sample_size = len(coords)\n        self.temp = temp\n        self.alpha = alpha\n        self.stopping_temp = stopping_temp\n        self.stopping_iter = stopping_iter\n        self.iteration = 1\n\n        self.dist_matrix = tsp_utils.vectorToDistMatrix(coords)\n        self.curr_solution = tsp_utils.nearestNeighbourSolution(self.dist_matrix)\n        self.best_solution = self.curr_solution\n\n        self.solution_history = [self.curr_solution]\n\n        self.curr_weight = self.weight(self.curr_solution)\n        self.initial_weight = self.curr_weight\n        self.min_weight = self.curr_weight\n\n        self.weight_list = [self.curr_weight]\n\n        print('Intial weight: ', self.curr_weight)\n\n    def weight(self, sol):\n        return sum([self.dist_matrix[i, j] for i, j in zip(sol, sol[1:] + [sol[0]])])\n\n    def acceptance_probability(self, candidate_weight):\n        return math.exp(-abs(candidate_weight - self.curr_weight) / self.temp)\n\n    def accept(self, candidate):\n        candidate_weight = self.weight(candidate)\n        if candidate_weight < self.curr_weight:\n            self.curr_weight = candidate_weight\n            self.curr_solution = candidate\n            if candidate_weight < self.min_weight:\n                self.min_weight = candidate_weight\n                self.best_solution = candidate\n\n        else:\n            if random.random() < self.acceptance_probability(candidate_weight):\n                self.curr_weight = candidate_weight\n                self.curr_solution = candidate\n\n    def anneal(self):\n        while self.temp >= self.stopping_temp and self.iteration < self.stopping_iter:\n            candidate = list(self.curr_solution)\n            l = random.randint(2, self.sample_size - 1)\n            i = random.randint(0, self.sample_size - l)\n\n            candidate[i: (i + l)] = reversed(candidate[i: (i + l)])\n\n            self.accept(candidate)\n            self.temp *= self.alpha\n            self.iteration += 1\n            self.weight_list.append(self.curr_weight)\n            self.solution_history.append(self.curr_solution)\n        print('----------------using simulated annealing------------------')\n        print('Minimum weight: ', self.min_weight)\n        print('Improvement: ',\n              round((self.initial_weight - self.min_weight) / (self.initial_weight), 4) * 100, '%')\n\n    def animateSolutions(self):\n        animated_visualizer.animateTSP(self.solution_history, self.coords)\n\n    def plotLearning(self):\n        plt.plot([i for i in range(len(self.weight_list))], self.weight_list)\n        line_init = plt.axhline(y=self.initial_weight, color='r', linestyle='--')\n        line_min = plt.axhline(y=self.min_weight, color='g', linestyle='--')\n        plt.legend([line_init, line_min], ['Initial weight', 'Optimized weight'])\n        plt.ylabel('Weight')\n        plt.xlabel('Iteration')\n        plt.show()\n",
      "name_column": 6,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_sa.py(name_duplicate_version)",
        "TSP/tsp_sa.py/main(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "\nThe TSP (Traveling Salesman Problem) simulated annealing algorithm uses the following parameters and attributes:\n\nParameters and Attributes:\n\n* `coords`: a list of coordinates representing the cities to be visited by the salesman\n* `temp`: initial temperature for the annealing process\n* `alpha`: cooling rate for the annealing process\n* `stopping_temp`: stopping temperature for the annealing process\n* `stopping_iter`: maximum number of iterations before the algorithm stops\n\nAttributes:\n\n* `dist_matrix`: a matrix containing distances between all pairs of cities\n* `curr_solution`: the current solution, represented as a list of city indices\n* `best_solution`: the best solution found so far, which is initially set to the nearest-neighbour solution\n* `solution_history`: a list containing all solutions generated during the annealing process\n* `curr_weight`: the weight of the current solution, calculated using the Euclidean distance between cities\n* `initial_weight`: the initial weight of the TSP instance\n* `min_weight`: the minimum weight found so far, initially set to the initial weight\n* `weight_list`: a list containing all weights generated during the annealing process\n\nNotes:\n\n* The function is used to initialize the simulated annealing algorithm for the TSP.\n* It sets the initial parameters and attributes required for the annealing process, including the distance matrix, current solution, best solution, and solution history.\n* The weight of the current solution is calculated using the Euclidean distance between cities.\n* The stopping temperature and maximum number of iterations are used to control the convergence of the algorithm.\n* The initial weight, minimum weight, and weight list are used for monitoring the progress of the annealing process."
      ],
      "code_start_line": 9,
      "code_end_line": 31,
      "params": [
        "self",
        "coords",
        "temp",
        "alpha",
        "stopping_temp",
        "stopping_iter"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, coords, temp, alpha, stopping_temp, stopping_iter):\n\n        self.coords = coords\n        self.sample_size = len(coords)\n        self.temp = temp\n        self.alpha = alpha\n        self.stopping_temp = stopping_temp\n        self.stopping_iter = stopping_iter\n        self.iteration = 1\n\n        self.dist_matrix = tsp_utils.vectorToDistMatrix(coords)\n        self.curr_solution = tsp_utils.nearestNeighbourSolution(self.dist_matrix)\n        self.best_solution = self.curr_solution\n\n        self.solution_history = [self.curr_solution]\n\n        self.curr_weight = self.weight(self.curr_solution)\n        self.initial_weight = self.curr_weight\n        self.min_weight = self.curr_weight\n\n        self.weight_list = [self.curr_weight]\n\n        print('Intial weight: ', self.curr_weight)\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [],
      "reference_who": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/weight(name_duplicate_version)",
        "TSP/tsp_utils.py/vectorToDistMatrix(name_duplicate_version)",
        "TSP/tsp_utils.py/nearestNeighbourSolution(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "weight",
      "md_content": [
        "\nweight(self, sol)\n\nThe `weight` function is a method that calculates the total cost of a given solution (sol) by summing up the distances between each pair of cities in the solution. It takes an instance of the `SimulatedAnnealing` class as an input and returns a float value representing the total weight of the solution.\n\nParameters:\n\n* `self`: An instance of the `SimulatedAnnealing` class.\n* `sol`: A list of integers representing the cities in the solution. Each integer is an index to the city array in the `SimulatedAnnealing` class.\n\nReturns:\n\n* The total weight of the solution, represented as a float value.\n\nNotes:\n\n* The function iterates over each pair of adjacent cities in the solution and calculates the distance between them using the `dist_matrix` attribute. It then adds these distances to the total weight of the solution.\n* If an edge case occurs where a city is not included in the solution, it will be handled by returning a `ValueError`.\n* The function returns the total weight of the solution, which can be used for evaluation purposes during testing.\n\nTesting Notes:\n\n* The `weight` function should be tested with different solutions to ensure that it calculates the correct weight value.\n* Edge cases such as empty or null solutions should be handled correctly and return a `ValueError`.\n* Tests can be written to check if the function returns the correct weight value for various inputs, such as a solution with all cities visited in order or a solution with some cities missing.\n* Tests can also be written to check if the function handles invalid input correctly by returning the correct error message and type."
      ],
      "code_start_line": 33,
      "code_end_line": 34,
      "params": [
        "self",
        "sol"
      ],
      "have_return": true,
      "code_content": "    def weight(self, sol):\n        return sum([self.dist_matrix[i, j] for i, j in zip(sol, sol[1:] + [sol[0]])])\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/__init__(name_duplicate_version)",
        "TSP/simulated_annealing.py/SimulatedAnnealing/accept(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "acceptance_probability",
      "md_content": [
        "\n### Acceptance Probability Function Documentation\n\nThe `acceptance_probability` function is a crucial part of the Simulated Annealing algorithm used to determine whether a new solution should be accepted or rejected. The function takes in a candidate weight and returns an acceptance probability based on the difference between the candidate weight and the current weight, as well as a temperature parameter that controls the cooling rate.\n\nThe `acceptance_probability` function is defined as follows:\n```python\ndef acceptance_probability(self, candidate_weight):\n    return math.exp(-abs(candidate_weight - self.curr_weight) / self.temp)\n```\nThe function uses the exponential formula to calculate the acceptance probability based on the difference between the candidate weight and the current weight, as well as the temperature parameter. The `self` parameter refers to the instance of the SimulatedAnnealing class that calls this function.\n\nTo test this function effectively, it is important to consider edge cases and error handling scenarios. Here are some examples:\n\n* **Edge case 1**: If the candidate weight is equal to the current weight, the acceptance probability should be 1.0. This ensures that no matter what the temperature parameter is set to, the new solution will always be accepted if it has the same weight as the current best solution.\n* **Error handling scenario 1**: If the candidate weight is not a number or is not within the expected range (e.g., negative), the function should raise an error. This ensures that the function works correctly only when the input values are valid and appropriate for the calculation.\n* **Edge case 2**: If the temperature parameter is set to zero, the acceptance probability should be 1.0. This ensures that even if the cooling rate is very slow, the new solution will always be accepted if it has the same weight as the current best solution.\n\nTo ensure that the `acceptance_probability` function works correctly in different scenarios, it is important to test the function with a variety of inputs and parameters. The following table lists some example input values and their corresponding outputs:\n```\n| Candidate Weight | Current Weight | Temperature | Acceptance Probability |\n| --------------- | -------------- | ----------- | --------------------- |\n| 10              | 5              | 1           | 0.3679                |\n| 12              | 5              | 2           | 0.4466                |\n| 15              | 5              | 3           | 0.5                   |\n| 20              | 5              | 4           | 0.6321                |\n```\nAs can be seen from the table, the acceptance probability increases as the difference between the candidate weight and the current weight decreases, but reaches a maximum value of 1 when the difference is zero. The temperature parameter controls the cooling rate, which affects the acceptance probability in a non-linear way.\n\nIn conclusion, the `acceptance_probability` function is a critical component of the Simulated Annealing algorithm that determines whether a new solution should be accepted or rejected based on its weight and the current temperature parameter. It is important to test this function with various input values and parameters to ensure that it works correctly in different scenarios, and to identify any edge cases or error handling scenarios that may arise during testing."
      ],
      "code_start_line": 36,
      "code_end_line": 37,
      "params": [
        "self",
        "candidate_weight"
      ],
      "have_return": true,
      "code_content": "    def acceptance_probability(self, candidate_weight):\n        return math.exp(-abs(candidate_weight - self.curr_weight) / self.temp)\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/accept(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "accept",
      "md_content": [
        "Documentation for accept() in simulated_annealing.py\n-----------------------------------------------\n\n### Introduction\nThe `accept` function is a critical part of the Simulated Annealing algorithm used to determine whether a candidate solution should be accepted or not. This function takes two parameters: a `candidate` and its weight. The function evaluates the candidate's weight and decides whether it should be accepted as the new current solution based on various factors such as the weight of the candidate, the acceptance probability, and the minimum weight reached so far.\n\n### Parameters\nThe function takes two parameters:\n* `candidate`: a list representing a potential solution for the TSP problem.\n* `candidate_weight`: the weight of the candidate solution.\n\n### Return values\nThe function returns a boolean value indicating whether the candidate should be accepted as the new current solution based on its weight and other factors. The return value is `True` if the candidate is accepted, and `False` otherwise.\n\n### Error handling\nThe function raises an error if the input parameters are not valid or if there is a problem with the acceptance probability calculation.\n\n### Edge cases\n* If the weight of the candidate solution is less than the current minimum weight, the function accepts the new candidate as the best solution and updates the minimum weight accordingly.\n* If the weight of the candidate solution is greater than or equal to the current minimum weight, the function calculates the acceptance probability based on the current temperature and the weight difference between the candidate and the current solution. If the acceptance probability is greater than a random value generated by `random.random()`, the function accepts the new candidate as the current solution.\n* If the input parameters are invalid or if there is a problem with the acceptance probability calculation, the function raises an error.\n\n### Notes\nThe acceptance probability is calculated based on the Boltzmann distribution, which is a probability distribution that depends on the temperature and the weight difference between two solutions. The higher the temperature, the greater the acceptance probability of accepting a new solution that is worse than the current one. The function uses the `acceptance_probability` method to calculate the acceptance probability for each candidate solution based on its weight and the current temperature.\n\n### Conclusion\nIn conclusion, the `accept` function is an essential part of the Simulated Annealing algorithm that determines whether a potential solution should be accepted as the new current solution based on various factors such as its weight, the acceptance probability, and the minimum weight reached so far. The function ensures that the current solution is updated accordingly to reflect the best possible solution found by the algorithm during its execution."
      ],
      "code_start_line": 39,
      "code_end_line": 51,
      "params": [
        "self",
        "candidate"
      ],
      "have_return": false,
      "code_content": "    def accept(self, candidate):\n        candidate_weight = self.weight(candidate)\n        if candidate_weight < self.curr_weight:\n            self.curr_weight = candidate_weight\n            self.curr_solution = candidate\n            if candidate_weight < self.min_weight:\n                self.min_weight = candidate_weight\n                self.best_solution = candidate\n\n        else:\n            if random.random() < self.acceptance_probability(candidate_weight):\n                self.curr_weight = candidate_weight\n                self.curr_solution = candidate\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/anneal(name_duplicate_version)"
      ],
      "reference_who": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/weight(name_duplicate_version)",
        "TSP/simulated_annealing.py/SimulatedAnnealing/acceptance_probability(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "anneal",
      "md_content": [
        "\nDocumentation for `anneal` Function in Simulated Annealing Class:\n============================================================\n\nThe `anneal` function is a core method of the Simulated Annealing class that is used to perform simulated annealing on the input problem. The function takes no arguments and returns nothing, but it modifies several attributes of the object. Here is a detailed documentation for the `anneal` function:\n\n### Function Description\nThe `anneal` function performs simulated annealing on the current solution using a cooling schedule. It iteratively applies a series of operations to the current solution, and each operation has a probability of being accepted based on the temperature. The function stops when the temperature reaches a minimum threshold or the maximum number of iterations is reached.\n\n### Function Parameters\nThere are no parameters for the `anneal` function. However, the following attributes of the Simulated Annealing object are used:\n\n* `temp`: The current temperature of the annealing process. This attribute should be a positive float value.\n* `stopping_temp`: The minimum temperature at which to stop the annealing process. This attribute should also be a positive float value.\n* `alpha`: The cooling schedule parameter that determines how fast the temperature decreases during the annealing process. This attribute should be a positive float value between 0 and 1.\n* `stopping_iter`: The maximum number of iterations to perform during the annealing process. This attribute should be a positive integer value.\n* `initial_weight`: The weight of the initial solution. This attribute is used for bookkeeping purposes only.\n* `min_weight`: The minimum weight found during the annealing process. This attribute is used for bookkeeping purposes only.\n* `curr_solution`: The current solution being annealed. This attribute should be a list of integers representing the solution.\n* `curr_weight`: The weight of the current solution. This attribute is used for bookkeeping purposes only.\n* `weight_list`: A list containing the weights of all solutions found during the annealing process. This attribute is used for bookkeeping purposes only.\n* `solution_history`: A list containing all solutions found during the annealing process, including the initial solution. This attribute is used for bookkeeping purposes only.\n\n### Function Return Value\nThe function returns nothing but modifies several attributes of the Simulated Annealing object, including:\n\n* `temp`: The new temperature after the iteration.\n* `iteration`: The number of iterations performed during the annealing process.\n* `weight_list`: A list containing the weights of all solutions found during the annealing process.\n* `solution_history`: A list containing all solutions found during the annealing process, including the initial solution.\n\n### Edge Cases and Error Handling\nThe `anneal` function should handle edge cases such as:\n\n* The temperature reaching zero before the stopping threshold is reached. In this case, the function should terminate immediately without making any further changes to the attributes of the Simulated Annealing object.\n* The maximum number of iterations being reached before the stopping threshold is reached. In this case, the function should terminate immediately without making any further changes to the attributes of the Simulated Annealing object.\n\nThe `anneal` function should also handle errors such as:\n\n* An invalid value for the temperature or stopping threshold. In this case, the function should raise a ValueError exception.\n* A non-integer value for the maximum number of iterations. In this case, the function should raise a TypeError exception.\n\n### Return Values\nThe `anneal` function returns nothing but modifies several attributes of the Simulated Annealing object, including:\n\n* `temp`: The new temperature after the iteration.\n* `iteration`: The number of iterations performed during the annealing process.\n* `weight_list`: A list containing the weights of all solutions found during the annealing process.\n* `solution_history`: A list containing all solutions found during the annealing process, including the initial solution.\n\n### Notes\nThe `anneal` function is a core method of the Simulated Annealing class that performs simulated annealing on the input problem using a cooling schedule. The function takes no arguments and returns nothing but modifies several attributes of the object, including the temperature, iteration count, weight list, and solution history. The function should handle edge cases and errors appropriately and return appropriate values."
      ],
      "code_start_line": 53,
      "code_end_line": 69,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def anneal(self):\n        while self.temp >= self.stopping_temp and self.iteration < self.stopping_iter:\n            candidate = list(self.curr_solution)\n            l = random.randint(2, self.sample_size - 1)\n            i = random.randint(0, self.sample_size - l)\n\n            candidate[i: (i + l)] = reversed(candidate[i: (i + l)])\n\n            self.accept(candidate)\n            self.temp *= self.alpha\n            self.iteration += 1\n            self.weight_list.append(self.curr_weight)\n            self.solution_history.append(self.curr_solution)\n        print('----------------using simulated annealing------------------')\n        print('Minimum weight: ', self.min_weight)\n        print('Improvement: ',\n              round((self.initial_weight - self.min_weight) / (self.initial_weight), 4) * 100, '%')\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_sa.py/main(name_duplicate_version)"
      ],
      "reference_who": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/accept(name_duplicate_version)"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "animateSolutions",
      "md_content": [
        "animateSolutions is a function that visualizes the traveling salesman problem (TSP) solution history using simulated annealing algorithm. This function takes no parameters and returns nothing.\nIt is part of the animateSolutions class, which is responsible for animating the TSP solution history.\nThe function first calls the animateTSP method from the animated visualizer object, passing in two parameters: solution_history and coords.\nsolution_history is an array of integers that represents the traveling salesman problem solution history. Coords is an array of floats that represent the coordinates of each city in the TSP instance.\nThe animateTSP method uses these parameters to generate an animation of the TSP solution history, showing how the solution changes over time.\nNote: If you are a tester, it is essential to thoroughly test this function to ensure that it works correctly and produces the expected results."
      ],
      "code_start_line": 71,
      "code_end_line": 72,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def animateSolutions(self):\n        animated_visualizer.animateTSP(self.solution_history, self.coords)\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_sa.py/main(name_duplicate_version)"
      ],
      "reference_who": [
        "TSP/animated_visualizer.py/animateTSP(name_duplicate_version)"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "plotLearning",
      "md_content": [
        "\nplotLearning: A Function for Visualizing the Learning Process of Simulated Annealing\n===============================================================================\n\nThe `plotLearning` function is a part of the `SimulatedAnnealing` class in TSP. This function is used to visualize the learning process of simulated annealing by plotting the weight of each iteration against the iteration number. The function takes no parameters and returns nothing, but it displays a graph with several key elements.\n\nKey Features of `plotLearning`\n------------------------------\n\n1. **Initial Weight:** The initial weight is represented by a red line that is dashed. This line shows the starting point for simulated annealing and serves as a reference for comparison.\n2. **Optimized Weight:** The optimized weight is represented by a green line that is also dashed. This line shows the lowest weight achieved during the simulation, which represents the optimized solution found by simulated annealing.\n3. **Iteration Number:** The iteration number is plotted on the x-axis of the graph. Each point in the graph corresponds to one iteration of simulated annealing, and the weight at each point represents the weight achieved during that iteration.\n4. **Weight:** The weight is plotted on the y-axis of the graph. This represents the objective function being optimized by simulated annealing, and higher weights indicate a worse solution than lower weights.\n5. **Legend:** The legend shows the labels for the two lines representing the initial weight and the optimized weight.\n\nEdge Cases and Error Handling\n-----------------------------\n\n1. **Empty List of Weights:** If the `weight_list` attribute is empty, an error will be thrown by the `range()` function when trying to plot the graph. In this case, the user should check that the `SimulatedAnnealing` instance has a non-empty `weight_list` before calling the `plotLearning` function.\n2. **Non-Numeric Weights:** If any of the weights in the `weight_list` attribute are not numeric, an error will be thrown by the `plt.plot()` function when trying to plot the graph. In this case, the user should check that all the weights in the list are numeric before calling the `plotLearning` function.\n3. **Invalid Initial Weight:** If the initial weight is negative or non-numeric, an error will be thrown by the `plt.axhline()` function when trying to plot the graph. In this case, the user should check that the initial weight is a positive number before calling the `plotLearning` function.\n4. **Invalid Min Weight:** If the minimum weight is negative or non-numeric, an error will be thrown by the `plt.axhline()` function when trying to plot the graph. In this case, the user should check that the minimum weight is a positive number before calling the `plotLearning` function.\n5. **Insufficient Data:** If there are not enough points in the `weight_list` attribute to create a valid graph, an error will be thrown by the `plt.plot()` function when trying to plot the graph. In this case, the user should check that the `weight_list` attribute has enough data points before calling the `plotLearning` function.\n\nReturn Values\n-------------\n\nThe `plotLearning` function does not return any values. However, it displays a graph with several key elements.\n\nConclusion\n----------\n\nIn conclusion, the `plotLearning` function is an important part of the `SimulatedAnnealing` class in TSP that helps users visualize the learning process of simulated annealing. The function has several key features, including plotting the weight of each iteration against the iteration number, representing the initial weight and optimized weight with dashed lines, and displaying a legend showing the labels for the two lines representing the initial weight and the optimized weight. The function also handles edge cases and errors related to empty lists of weights, non-numeric weights, invalid initial or minimum weights, and insufficient data points. By using this function, users can gain a better understanding of how simulated annealing works and how it finds the optimal solution for the Traveling Salesman Problem."
      ],
      "code_start_line": 74,
      "code_end_line": 81,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def plotLearning(self):\n        plt.plot([i for i in range(len(self.weight_list))], self.weight_list)\n        line_init = plt.axhline(y=self.initial_weight, color='r', linestyle='--')\n        line_min = plt.axhline(y=self.min_weight, color='g', linestyle='--')\n        plt.legend([line_init, line_min], ['Initial weight', 'Optimized weight'])\n        plt.ylabel('Weight')\n        plt.xlabel('Iteration')\n        plt.show()\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_sa.py/main(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "TSP/tsp_sa.py": [
    {
      "type": "FunctionDef",
      "name": "main",
      "md_content": [
        "\nDocumentation for Main:\n\nIntroduction:\n-------------\n\nThe main function is the entry point of the program, and it is responsible for setting up and running the simulated annealing algorithm with 2-opt. The function takes no arguments and has no return values.\n\nSetting Simulated Annealing Algorithm Parameters:\n-----------------------------------------------\n\nInside the main function, we set the parameters of the simulated annealing algorithm. These parameters include:\n\n* temperature (temp): This is the starting temperature for the simulated annealing algorithm, and it is set to 1000.\n* stopping temperature (stopping_temp): This is the temperature at which the simulated annealing algorithm will stop if no improvement in the solution has been found after a certain number of iterations. We set this to 0.00000001, indicating that the algorithm should stop when the temperature is very close to zero.\n* alpha (alpha): This is the cooling rate for the simulated annealing algorithm, and it is set to 0.9995. This value determines how quickly the temperature decreases during the algorithm's execution.\n* stopping iteration (stopping_iter): This is the maximum number of iterations that the simulated annealing algorithm will run for before stopping. We set this to 10000000, indicating that the algorithm should run for at least one million iterations.\n\nSetting Dimensions of Grid:\n--------------------------\n\nNext, we set the dimensions of the grid on which the simulated annealing algorithm will operate. These dimensions include:\n\n* size width (size_width): This is the number of nodes in the horizontal direction that make up the grid. We set this to 200.\n* size height (size_height): This is the number of nodes in the vertical direction that make up the grid. We set this to 200.\n\nGenerating Random List of Nodes:\n------------------------------\n\nNext, we generate a random list of nodes for the simulated annealing algorithm to operate on. The NodeGenerator class is used to generate these nodes.\n\nRunning Simulated Annealing Algorithm with 2-Opt:\n---------------------------------------------\n\nWith the list of nodes generated, we now run the simulated annealing algorithm with 2-opt. We pass the list of nodes, the temperature, alpha, stopping temperature, and stopping iteration as parameters to the SimulatedAnnealing class constructor. The anneal() method is then called on the object to execute the algorithm.\n\nAnimating:\n----------\n\nAfter running the simulated annealing algorithm with 2-opt, we animate the solutions generated by the algorithm using the animateSolutions() method of the SimulatedAnnealing class. This method generates a visual representation of the solutions found by the algorithm.\n\nShowing Improvement over Time:\n-------------------------------\n\nFinally, we show the improvement in the objective function value over time using the plotLearning() method of the SimulatedAnnealing class. This method plots the objective function values generated by the algorithm as a function of the number of iterations.\n\nNotes:\n-----\n\n* The simulated annealing algorithm with 2-opt is run for at least one million iterations, and it will stop if no improvement in the solution has been found after a certain number of iterations.\n* The cooling rate (alpha) determines how quickly the temperature decreases during the execution of the algorithm, and we set this to 0.9995.\n* The temperature at which the algorithm stops is determined by the stopping temperature, and we set this to 0.00000001, indicating that the algorithm should stop when the temperature is very close to zero."
      ],
      "code_start_line": 4,
      "code_end_line": 28,
      "params": [],
      "have_return": false,
      "code_content": "def main():\n    '''set the simulated annealing algorithm params'''\n    temp = 1000\n    stopping_temp = 0.00000001\n    alpha = 0.9995\n    stopping_iter = 10000000\n    '''set the dimensions of the grid'''\n    size_width = 200\n    size_height = 200\n\n    '''set the number of nodes'''\n    population_size = 70\n\n    '''generate random list of nodes'''\n    nodes = NodeGenerator(size_width, size_height, population_size).generate()\n\n    '''run simulated annealing algorithm with 2-opt'''\n    sa = SimulatedAnnealing(nodes, temp, alpha, stopping_temp, stopping_iter)\n    sa.anneal()\n\n    '''animate'''\n    sa.animateSolutions()\n\n    '''show the improvement over time'''\n    sa.plotLearning()\n",
      "name_column": 4,
      "item_status": "doc_upto_date",
      "who_reference_me": [],
      "reference_who": [
        "TSP/nodes_generator.py/NodeGenerator(name_duplicate_version)",
        "TSP/nodes_generator.py/NodeGenerator/generate(name_duplicate_version)",
        "TSP/simulated_annealing.py/SimulatedAnnealing(name_duplicate_version)",
        "TSP/simulated_annealing.py/SimulatedAnnealing/anneal(name_duplicate_version)",
        "TSP/simulated_annealing.py/SimulatedAnnealing/animateSolutions(name_duplicate_version)",
        "TSP/simulated_annealing.py/SimulatedAnnealing/plotLearning(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    }
  ],
  "TSP/tsp_utils.py": [
    {
      "type": "FunctionDef",
      "name": "vectorToDistMatrix",
      "md_content": [
        "\n---\n\n**vectorToDistMatrix**\n=====================\n\nThe `vectorToDistMatrix` function creates a distance matrix from an input vector of coordinates. This function is used as part of the TSP problem, where the goal is to find the shortest path that visits all cities exactly once and returns to the starting city. The `vectorToDistMatrix` function takes a 2D numpy array of coordinates as its only parameter, and it returns a 2D numpy array representing the distance matrix between each pair of cities.\n\n**Parameters**\n--------------\n\nThe `vectorToDistMatrix` function takes a single parameter, which is a 2D numpy array of floats representing the coordinates of the cities. The number of rows in this array should be equal to the number of cities, and the number of columns in this array should be equal to the number of dimensions (2 for a city). For example, if we have a TSP problem with 5 cities, each represented by a 2D vector of floats, the input array would look like this:\n```python\n[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0], [9.0, 10.0]]\n```\nThe function assumes that the input coordinates are valid and in the correct format. Invalid or malformed input may result in errors being raised during the execution of the function.\n\n**Return Value**\n--------------\n\nThe `vectorToDistMatrix` function returns a 2D numpy array representing the distance matrix between each pair of cities. The shape of this array is `(n, n)`, where `n` is the number of cities in the input vector. Each element of the array represents the Euclidean distance between the corresponding pair of cities, rounded to the nearest integer. For example, if we have a TSP problem with 5 cities and their coordinates are:\n```python\n[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0], [9.0, 10.0]]\n```\nThe output distance matrix would look like this:\n```python\n[[0, 2.23606798, 3.1622776, 4.47213595, 5.0],\n [2.23606798, 0, 2.23606798, 3.84165736, 5.0],\n [3.1622776, 2.23606798, 0, 4.12310563, 5.0],\n [4.47213595, 3.84165736, 4.12310563, 0, 5.0],\n [5.0, 5.0, 5.0, 5.0, 0]]\n```\nThe function assumes that the input coordinates are valid and in the correct format. Invalid or malformed input may result in errors being raised during the execution of the function.\n\n**Edge Cases**\n--------------\n\nThe `vectorToDistMatrix` function does not have any edge cases. However, it is important to note that the input coordinates must be valid and in the correct format for the function to produce accurate results. Invalid or malformed input may result in errors being raised during the execution of the function.\n\n**Error Handling**\n--------------\n\nThe `vectorToDistMatrix` function raises an error if the input coordinates are invalid or malformed. The error message will indicate what went wrong and how to fix it. For example, if the input array is not a 2D numpy array of floats, the function will raise a `TypeError` with the message \"Input must be a 2D numpy array of floats.\"\n\n**Notes**\n--------\n\nThe `vectorToDistMatrix` function is used as part of the TSP problem, where the goal is to find the shortest path that visits all cities exactly once and returns to the starting city. The function assumes that the input coordinates are valid and in the correct format. Invalid or malformed input may result in errors being raised during the execution of the function."
      ],
      "code_start_line": 6,
      "code_end_line": 10,
      "params": [
        "coords"
      ],
      "have_return": true,
      "code_content": "def vectorToDistMatrix(coords):\n    '''\n    Create the distance matrix\n    '''\n    return np.sqrt((np.square(coords[:, np.newaxis] - coords).sum(axis=2)))\n",
      "name_column": 4,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/__init__(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/__init__(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "nearestNeighbourSolution",
      "md_content": [
        "\nDocumentation for nearestNeighbourSolution Function:\n===============================================\n\nIntroduction:\n-------------\n\nThe `nearestNeighbourSolution` function is a part of the TSP (Traveling Salesman Problem) solver and is used to compute an initial solution based on the nearest neighbour strategy. The function takes in a distance matrix as its input and returns a list of nodes that form the tour.\n\nParameters:\n-------------\n\n* `dist_matrix`: A two-dimensional array representing the distances between all pairs of nodes in the graph.\n\nReturns:\n---------\n\n* A list of nodes that form the tour, where each node is visited exactly once and the tour starts and ends at the same node as the input matrix.\n\nCode Description:\n-------------------\n\nThe function starts by selecting a random starting node from the distance matrix using `random.randrange`. The `nodes_to_visit` list is then initialized with all the nodes in the graph except for the starting node. The nearest node to the starting node is found using the minimum distance between the starting node and each node in the `nodes_to_visit` list, and the function repeats this process until all nodes have been visited exactly once.\n\nNotes:\n-----\n\n* If any of the input nodes in the distance matrix are not connected to each other (i.e., there is no path between them), the function will return an error.\n* The function assumes that the distance matrix has a symmetric structure, meaning that the distances from node A to node B are the same as the distances from node B to node A. If this assumption is not met, the function may produce incorrect results.\n* The function uses the `random.randrange` function to select a random starting node from the distance matrix, which means that the output tour will vary each time it is run. To obtain consistent results, the function can be modified to use a specific seed value for the random number generator.\n* The function does not handle negative edge weights in the distance matrix, meaning that if any of the distances are negative, the function will return an error."
      ],
      "code_start_line": 13,
      "code_end_line": 29,
      "params": [
        "dist_matrix"
      ],
      "have_return": true,
      "code_content": "def nearestNeighbourSolution(dist_matrix):\n    '''\n    Computes the initial solution (nearest neighbour strategy)\n    '''\n    node = random.randrange(len(dist_matrix))\n    result = [node]\n\n    nodes_to_visit = list(range(len(dist_matrix)))\n    nodes_to_visit.remove(node)\n\n    while nodes_to_visit:\n        nearest_node = min([(dist_matrix[node][j], j) for j in nodes_to_visit], key=lambda x: x[0])\n        node = nearest_node[1]\n        nodes_to_visit.remove(node)\n        result.append(node)\n\n    return result\n",
      "name_column": 4,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/simulated_annealing.py/SimulatedAnnealing/__init__(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/__init__(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "TSP/tsp_vns.py": [
    {
      "type": "FunctionDef",
      "name": "main",
      "md_content": [
        "\nDocumentation for main:\n\nThe main function is responsible for setting up and running the simulated annealing algorithm with the variable neighborhood search (VNS) technique. It takes no input parameters but relies on several global variables to configure the algorithm's settings, such as the number of nodes (population size), the dimensions of the grid, and the stopping iteration.\n\nThe main function first sets up the simulated annealing algorithm with the given parameters. The stopping iteration is set to 10,000, while the population size is set to 20, and the dimensions of the grid are set to 200x200. The function then generates a random list of nodes using the NodeGenerator class.\n\nNext, the main function runs the simulated annealing algorithm with the VNS technique. This involves iteratively applying the VNS operator to find the optimal solution for each iteration. The algorithm stops when the stopping iteration is reached or when the best solution found during the simulation is the same as the initial solution provided.\n\nAfter running the algorithm, the main function animates the solutions using the animateSolutions() method and plots the learning curve using the plotLearning() method. These visualizations can be useful for testers to understand how the algorithm converges to a optimal solution over time.\n\nEdge Cases:\nThe edge cases that need to be considered when testing this function are:\n\n1. Empty or invalid input parameters: Testing with different combinations of valid and invalid input parameters, such as empty strings, negative numbers, or out-of-range values, can help identify potential errors in the code.\n2. Out-of-memory conditions: Testing for large population sizes or grid dimensions can help identify potential memory issues that may occur during execution.\n3. Algorithm convergence: Testing with different stopping iterations or population sizes can help ensure that the algorithm converges to a optimal solution within the given time frame.\n\nError Handling:\nThe main function includes error handling mechanisms such as exception handling and logging. When an error occurs during the execution of the algorithm, the function can catch the error and log it for further investigation. This helps prevent errors from crashing the program and ensures that testers can understand what went wrong.\n\nReturn Values:\nThe main function returns a tuple containing the best solution found during the simulation and the number of iterations required to find it. Testers can use this information to evaluate the performance of the algorithm and assess its convergence to an optimal solution.\n\nNotes:\n\n1. The main function is designed for demonstration purposes only, and its behavior may vary depending on the specific implementation.\n2. The variable neighborhood search (VNS) technique is a heuristic optimization method that uses local searches to find the global optimum. Testers can use this technique to evaluate the algorithm's ability to converge to an optimal solution in various scenarios.\n3. The animateSolutions() and plotLearning() methods are designed for visualizing and analyzing the algorithm's behavior. Testers can use these methods to understand how the algorithm behaves during execution and identify potential issues that may arise."
      ],
      "code_start_line": 4,
      "code_end_line": 21,
      "params": [],
      "have_return": false,
      "code_content": "def main():\n    '''set the simulated annealing algorithm params'''\n    stopping_iter = 10000\n    '''set the dimensions of the grid'''\n    size_width = 200\n    size_height = 200\n\n    '''set the number of nodes'''\n    population_size = 20\n\n    '''generate random list of nodes'''\n    nodes = NodeGenerator(size_width, size_height, population_size).generate()\n\n    '''run simulated annealing algorithm with 2-opt'''\n    vn = VariableNeighborhoodSearch(nodes, stopping_iter)\n    vn.vns()\n    vn.animateSolutions()\n    vn.plotLearning()\n",
      "name_column": 4,
      "item_status": "doc_upto_date",
      "who_reference_me": [],
      "reference_who": [
        "TSP/nodes_generator.py/NodeGenerator(name_duplicate_version)",
        "TSP/nodes_generator.py/NodeGenerator/generate(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/vns(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/animateSolutions(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/plotLearning(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    }
  ],
  "TSP/vns.py": [
    {
      "type": "ClassDef",
      "name": "VariableNeighborhoodSearch",
      "md_content": [
        "Variable Neighborhood Search (VNS) is a class used for solving Traveling Salesman Problems (TSP). The __init__ method takes in a list of coordinates and an integer stopping iteration as arguments. It initializes the dist_matrix, curr_solution, best_solution, solution_history, iterative number, min_weight, weight_list, and initial_weight attributes. \nThe local search function receives a candidate solution and returns a local search solution by swapping two adjacent nodes in the given solution. The shake method receives a current solution and an integer k as arguments and returns a random shaken solution of the candidate. The vns function uses a while loop to run until the stopping iteration is reached, where it iteratively shakes the current solution, updates its weight, and updates its best solution if the new weight is lower than the previous one. \nThe animateSolutions method is used for visualizing the solutions; and the plotLearning method is used for plotting the learning process of the class instance. The variables are used to track the iterations, weight, solution history, and best solution during the vns execution."
      ],
      "code_start_line": 9,
      "code_end_line": 95,
      "params": [],
      "have_return": true,
      "code_content": "class VariableNeighborhoodSearch:\n    def __init__(self, coords, stopping_iter):\n\n        self.coords = coords\n        self.sample_size = len(coords)\n        self.stopping_iter = stopping_iter\n        self.iteration = 1\n\n        self.dist_matrix = tsp_utils.vectorToDistMatrix(coords)\n        self.curr_solution = tsp_utils.nearestNeighbourSolution(self.dist_matrix)\n        self.best_solution = self.curr_solution\n\n        self.solution_history = [self.curr_solution]\n\n        self.curr_weight = self.weight(self.curr_solution)\n        self.initial_weight = self.curr_weight\n        self.min_weight = self.curr_weight\n\n        self.weight_list = [self.curr_weight]\n        print('-------------using variable neighborhood search-----------------')\n        print('Initial weight:', self.curr_weight)\n\n    def weight(self, sol):\n        return sum([self.dist_matrix[i, j] for i, j in zip(sol, sol[1:] + [sol[0]])])\n\n    def shake(self, solution, k):\n        candidate = list(solution)\n        for _ in range(k):\n            i = random.randint(0, self.sample_size - 1)\n            j = random.randint(0, self.sample_size - 1)\n            candidate[i], candidate[j] = candidate[j], candidate[i]\n        return candidate\n\n    def local_search(self, solution):\n        best_solution = list(solution)\n        best_weight = self.weight(best_solution)\n        improved = True\n\n        while improved:\n            improved = False\n            for i in range(self.sample_size - 1):\n                for j in range(i + 1, self.sample_size):\n                    candidate = list(best_solution)\n                    candidate[i], candidate[j] = candidate[j], candidate[i]\n                    candidate_weight = self.weight(candidate)\n                    if candidate_weight < best_weight:\n                        best_solution = candidate\n                        best_weight = candidate_weight\n                        improved = True\n\n        return best_solution\n\n    def vns(self):\n        while self.iteration < self.stopping_iter:\n            k = 1\n            while k <= self.sample_size:\n                candidate = self.shake(self.curr_solution, k)\n                candidate = self.local_search(candidate)\n                candidate_weight = self.weight(candidate)\n\n                if candidate_weight < self.curr_weight:\n                    self.curr_solution = candidate\n                    self.curr_weight = candidate_weight\n                    if candidate_weight < self.min_weight:\n                        self.min_weight = candidate_weight\n                        self.best_solution = candidate\n\n                k += 1\n                self.iteration += 1\n                self.weight_list.append(self.curr_weight)\n                self.solution_history.append(self.curr_solution)\n\n        print('Minimum weight:', self.min_weight)\n        print('Improvement:',\n              round((self.initial_weight - self.min_weight) / (self.initial_weight), 4) * 100, '%')\n\n    def animateSolutions(self):\n        animated_visualizer.animateTSP(self.solution_history, self.coords)\n\n    def plotLearning(self):\n        plt.plot([i for i in range(len(self.weight_list))], self.weight_list)\n        line_init = plt.axhline(y=self.initial_weight, color='r', linestyle='--')\n        line_min = plt.axhline(y=self.min_weight, color='g', linestyle='--')\n        plt.legend([line_init, line_min], ['Initial weight', 'Optimized weight'])\n        plt.ylabel('Weight')\n        plt.xlabel('Iteration')\n        plt.show()\n",
      "name_column": 6,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_vns.py(name_duplicate_version)",
        "TSP/tsp_vns.py/main(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "\nDocumentation for __init__ Function in TSP/vns.py/VariableNeighborhoodSearch Module:\n\nIntroduction:\nThe __init__ function is the constructor of the VariableNeighborhoodSearch class, which is used to initialize the variables and set up the necessary data structures for the optimization algorithm. The function takes two parameters: coords, which is a list of coordinates for the nodes in the TSP problem, and stopping_iter, which is the maximum number of iterations that the algorithm will perform before terminating.\n\nParameters:\n\n* coords (list): List of coordinates for the nodes in the TSP problem.\n* stopping_iter (int): Maximum number of iterations that the algorithm will perform before terminating.\n\nAttributes:\n\n* coords (list): Same as input parameter coords.\n* sample_size (int): Number of nodes in the TSP problem.\n* stopping_iter (int): Same as input parameter stopping_iter.\n* iteration (int): Current iteration number, starting at 1.\n* dist_matrix (numpy array): Distance matrix between all pairs of nodes in the TSP problem.\n* curr_solution (list): Current solution vector for the TSP problem.\n* best_solution (list): Best solution vector found so far for the TSP problem.\n* solution_history (list): List containing all solutions vectors found during optimization.\n* curr_weight (float): Weight of the current solution vector, calculated using the distance matrix and the weight function.\n* initial_weight (float): Initial weight of the best solution vector, used for comparison during optimization.\n* min_weight (float): Minimum weight found so far during optimization, used to determine termination conditions.\n* weight_list (list): List containing all weights calculated during optimization.\n\nCode Description:\nThe __init__ function first sets up the necessary data structures for the optimization algorithm by initializing the distance matrix and current solution vector using the input parameter coords. It then sets the best solution vector to be the same as the current solution vector, and initializes the list of weights calculated during optimization. The function also prints a message indicating that the variable neighborhood search algorithm is being used, and displays the initial weight of the current solution vector.\n\nNotes:\n\n* __init__ function should only be called once when creating an instance of the VariableNeighborhoodSearch class.\n* Input parameters coords and stopping_iter must be valid lists or numpy arrays with appropriate dimensions for the TSP problem being optimized.\n* The best_solution vector should be initialized to a feasible solution vector that is close to the optimal solution.\n* The initial weight of the best_solution vector is used during optimization to determine termination conditions based on the minimum weight found so far."
      ],
      "code_start_line": 10,
      "code_end_line": 29,
      "params": [
        "self",
        "coords",
        "stopping_iter"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, coords, stopping_iter):\n\n        self.coords = coords\n        self.sample_size = len(coords)\n        self.stopping_iter = stopping_iter\n        self.iteration = 1\n\n        self.dist_matrix = tsp_utils.vectorToDistMatrix(coords)\n        self.curr_solution = tsp_utils.nearestNeighbourSolution(self.dist_matrix)\n        self.best_solution = self.curr_solution\n\n        self.solution_history = [self.curr_solution]\n\n        self.curr_weight = self.weight(self.curr_solution)\n        self.initial_weight = self.curr_weight\n        self.min_weight = self.curr_weight\n\n        self.weight_list = [self.curr_weight]\n        print('-------------using variable neighborhood search-----------------')\n        print('Initial weight:', self.curr_weight)\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [],
      "reference_who": [
        "TSP/tsp_utils.py/vectorToDistMatrix(name_duplicate_version)",
        "TSP/tsp_utils.py/nearestNeighbourSolution(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/weight(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "weight",
      "md_content": [
        "Function Name: weight\n\nDescription: This function calculates the total weight of a given solution (sol) based on the distance matrix (dist_matrix) defined in the constructor of the VariableNeighborhoodSearch class. The weight is calculated by summing up the distances between all pairs of adjacent cities in the solution.\n\nParameters or Attributes:\n\n* sol: A list of integers representing the cities visited in a particular order.\n* dist_matrix: A two-dimensional list of floats where each element represents the distance between two adjacent cities. The first dimension corresponds to the source city and the second dimension corresponds to the destination city.\n\nCode Description:\nThe weight function uses the zip() function in Python to iterate over all pairs of adjacent cities in the solution sol, and then calculates the sum of their corresponding distances using the dist_matrix.\n\nNote: The weight function assumes that the input solution (sol) is a valid path in the graph represented by the distance matrix. If the input solution contains any repeated cities or invalid edges, the weight function may produce incorrect results. Therefore, it is important to test the function with a variety of inputs to ensure its correctness."
      ],
      "code_start_line": 31,
      "code_end_line": 32,
      "params": [
        "self",
        "sol"
      ],
      "have_return": true,
      "code_content": "    def weight(self, sol):\n        return sum([self.dist_matrix[i, j] for i, j in zip(sol, sol[1:] + [sol[0]])])\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/vns.py/VariableNeighborhoodSearch/__init__(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/local_search(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/vns(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "shake",
      "md_content": [
        "\n`shake()` is a function used to modify the solution of the `VariableNeighborhoodSearch` algorithm in the TSP/vns.py project by randomly swapping two nodes in the solution. This function takes two parameters:\n\n* `solution`: A list of integers representing the current solution.\n* `k`: An integer indicating the number of random swaps to perform on the solution.\n\nThe function first creates a copy of the input solution, and then performs `k` random swaps between nodes in the solution using the `random.randint()` method. Each swap involves exchanging the values of two nodes in the solution at random positions. After all swaps are performed, the modified solution is returned.\n\nNote that the function assumes that the input `solution` is a valid solution for the TSP problem and that `k` is a positive integer. If either of these conditions is not met, an error may occur. Therefore, it is important to test the function with appropriate inputs to ensure correct behavior.\n\nIn terms of testing, the following edge cases should be considered:\n\n* Testing with valid input solutions and varying values of `k` to check that the function correctly swaps nodes in the solution.\n* Testing with invalid input solutions (e.g., a solution with negative weights or cycles) to ensure that the function handles such inputs appropriately.\n* Testing with large values of `k` to check that the function can handle larger numbers of random swaps without causing performance issues.\n\nIn terms of error handling, it is important to ensure that the function gracefully handles invalid input parameters or unexpected errors during execution. This may involve using try-catch blocks or other error handling mechanisms to catch and report any exceptions that occur during the execution of the function.\n\nFinally, in terms of return values, it is important to document the expected output of the function for different inputs. For example, if the input solution has `n` nodes, the function should return a modified solution with `n` nodes after performing the random swaps. It may also be helpful to provide examples of how the function can be used in practice, such as how it might be integrated with other parts of the TSP/vns.py project.\n\nOverall, testing and documentation for the `shake()` function will help ensure that the function works correctly and provides reliable results when used within the context of the TSP/vns.py project."
      ],
      "code_start_line": 34,
      "code_end_line": 40,
      "params": [
        "self",
        "solution",
        "k"
      ],
      "have_return": true,
      "code_content": "    def shake(self, solution, k):\n        candidate = list(solution)\n        for _ in range(k):\n            i = random.randint(0, self.sample_size - 1)\n            j = random.randint(0, self.sample_size - 1)\n            candidate[i], candidate[j] = candidate[j], candidate[i]\n        return candidate\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/vns.py/VariableNeighborhoodSearch/vns(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "local_search",
      "md_content": [
        "\nlocal_search() is a function in TSP/vns.py/VariableNeighborhoodSearch that searches for the best solution within a given sample size. The following are its parameters and attributes:\n\n* Parameters:\n\t+ solution: list, the initial solution\n\t+ sample_size: int, the number of neighboring solutions to be considered\n* Attributes:\n\t+ best_solution: list, the best solution found so far\n\t+ best_weight: float, the weight of the best solution found so far\n\t+ improved: bool, whether a better solution has been found or not.\n\nThe function works by iteratively swapping neighboring cities within the initial solution and evaluating their weights. If a better solution is found, it replaces the current best solution. The loop continues until no improvement is made in the weight of the solution. The final best solution is returned.\n\nThe key aspects for testing are as follows:\n\n* Edge cases:\n\t+ Test the function with an empty list or tuple as input.\n\t+ Test the function with a list containing only one city.\n\t+ Test the function with a sample size of 1.\n* Error handling:\n\t+ Test the function with a negative or zero value for sample_size.\n\t+ Test the function with an invalid weight function that returns a non-numeric value.\n* Return values:\n\t+ Test the function with a valid input and check if it returns a list of cities representing the best solution found.\n\t+ Test the function with a valid input and check if it returns a float representing the weight of the best solution found.\n\t+ Test the function with an invalid input, such as a string or a list of cities that does not match the initial solution's structure, and check if it raises an error.\n\nOverall, testing the local_search() function involves verifying its behavior in various scenarios, including edge cases, error handling, and return values. By thoroughly testing these aspects, testers can ensure that the function works as intended and provides accurate results for different inputs."
      ],
      "code_start_line": 42,
      "code_end_line": 59,
      "params": [
        "self",
        "solution"
      ],
      "have_return": true,
      "code_content": "    def local_search(self, solution):\n        best_solution = list(solution)\n        best_weight = self.weight(best_solution)\n        improved = True\n\n        while improved:\n            improved = False\n            for i in range(self.sample_size - 1):\n                for j in range(i + 1, self.sample_size):\n                    candidate = list(best_solution)\n                    candidate[i], candidate[j] = candidate[j], candidate[i]\n                    candidate_weight = self.weight(candidate)\n                    if candidate_weight < best_weight:\n                        best_solution = candidate\n                        best_weight = candidate_weight\n                        improved = True\n\n        return best_solution\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/vns.py/VariableNeighborhoodSearch/vns(name_duplicate_version)"
      ],
      "reference_who": [
        "TSP/vns.py/VariableNeighborhoodSearch/weight(name_duplicate_version)"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "vns",
      "md_content": [
        "\nDocumentation for VNS Function:\n==============================\n\nThe `vns` function is a key component of the Variable Neighborhood Search algorithm in our project. It is responsible for performing the actual search and optimization process, using the provided stopping criteria to determine when to terminate the search. The function takes no parameters but uses several attributes to store the current state of the search, including the current solution, weight, iteration count, and minimum weight found so far.\n\nThe `vns` function works as follows: it starts by initializing a counter variable `k` to 1 and entering a while loop that continues until the iteration count exceeds the provided stopping criteria. Within this while loop, it iteratively performs the following actions:\n\n1. Generate a new candidate solution using the `shake` method with the current solution and the current iteration number.\n2. Perform local search on the candidate solution using the `local_search` method.\n3. Evaluate the weight of the candidate solution using the `weight` method.\n4. If the weight is lower than the current minimum weight, update the current solution, minimum weight, and best solution accordingly.\n5. Increment the iteration count by 1.\n6. Append the weight to a list of weights and append the current solution to a list of solutions.\n\nOnce the while loop terminates, the function prints the minimum weight found and the improvement ratio between the initial weight and the minimum weight. The `vns` function returns nothing but instead modifies its attributes, making it suitable for testing."
      ],
      "code_start_line": 61,
      "code_end_line": 83,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def vns(self):\n        while self.iteration < self.stopping_iter:\n            k = 1\n            while k <= self.sample_size:\n                candidate = self.shake(self.curr_solution, k)\n                candidate = self.local_search(candidate)\n                candidate_weight = self.weight(candidate)\n\n                if candidate_weight < self.curr_weight:\n                    self.curr_solution = candidate\n                    self.curr_weight = candidate_weight\n                    if candidate_weight < self.min_weight:\n                        self.min_weight = candidate_weight\n                        self.best_solution = candidate\n\n                k += 1\n                self.iteration += 1\n                self.weight_list.append(self.curr_weight)\n                self.solution_history.append(self.curr_solution)\n\n        print('Minimum weight:', self.min_weight)\n        print('Improvement:',\n              round((self.initial_weight - self.min_weight) / (self.initial_weight), 4) * 100, '%')\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_vns.py/main(name_duplicate_version)"
      ],
      "reference_who": [
        "TSP/vns.py/VariableNeighborhoodSearch/weight(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/shake(name_duplicate_version)",
        "TSP/vns.py/VariableNeighborhoodSearch/local_search(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "animateSolutions",
      "md_content": [
        "\nDocumentation for animateSolutions Function:\n\nThe animateSolutions function is a part of the Variable Neighborhood Search (VNS) algorithm in TSP/vns.py. The purpose of this function is to visualize the evolution of solutions during the search process.\n\nFunction Description:\n\nThe animateSolutions function takes no input parameters and returns nothing. However, it utilizes a solution history that is passed as an argument when the VNS algorithm is initialized. It also requires coordinates (coords) for the nodes in the problem. The function animates these solutions using the animated_visualizer module.\n\nParameters or Attributes:\n\n* solution_history: a list of lists containing the best solutions found by the algorithm during its search process. Each sublist represents a single solution and contains the node indices in the order they appear on the tour.\n* coords: a dictionary mapping each node index to its corresponding coordinates (x, y) in the plane.\n\nCode Description:\n\nThe animateSolutions function begins by using the animated_visualizer module to generate an animation of the given solution history and coordinates. It then loops through each sublist in the solution history and adds a new frame to the animation for each solution. Each frame includes the coordinates of the nodes and their connections, as well as the current cost of the tour.\n\nNotes:\n\n* Edge Cases: None.\n* Error Handling: The function does not handle any errors that may occur during the creation of the animation. If any issues arise during this process, they will be reflected in the final output of the animated visualization.\n* Return Values: None.\n\nConclusion:\nThe animateSolutions function is an essential part of the Variable Neighborhood Search (VNS) algorithm's visualization feature. It utilizes the animated_visualizer module to create a dynamic animation that shows the evolution of solutions during the search process. The function takes no input parameters and returns nothing, but it requires a solution history and coordinates for the nodes in the problem. The code description provides a detailed overview of the function's functionality, including its parameters, attributes, and return values."
      ],
      "code_start_line": 85,
      "code_end_line": 86,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def animateSolutions(self):\n        animated_visualizer.animateTSP(self.solution_history, self.coords)\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_vns.py/main(name_duplicate_version)"
      ],
      "reference_who": [
        "TSP/animated_visualizer.py/animateTSP(name_duplicate_version)"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "plotLearning",
      "md_content": [
        "\nplotLearning(self): Plots the learning progress of the algorithm\n-----------------------------------------------\n\n### Function Description:\n\nThis function plots the learning progress of the algorithm using matplotlib library's plotting functions. The weight list is plotted against the iteration number, with two horizontal lines representing the initial and optimized weights, respectively. The legend shows these two lines with corresponding labels.\n\nThe function takes no input arguments but relies on self attributes for its execution.\n\n### Edge Cases:\n\n* There are no edge cases to consider when testing this function.\n\n### Error Handling:\n\n* If the matplotlib library is not installed, an error will occur while executing this function.\n* The function assumes that the weight_list and initial_weight attributes exist in self. If they do not exist or have not been defined, the function will raise an exception.\n* If the min_weight attribute does not exist in self, the function will use the default value of 0 for plotting the optimized weight.\n\n### Return Values:\n\n* The function returns nothing but instead modifies the state of the self object by adding a new figure to the matplotlib library's pyplot.\n\n### Testing Considerations:\n\n* When testing this function, it is essential to ensure that the plot is displayed correctly on screen and that the horizontal lines represent the initial and optimized weights with their corresponding labels.\n* To test for edge cases, one can input a weight_list with only two values (initial and optimized) to ensure that the function can still generate a valid plot even when there are only two weights to compare.\n* The function assumes that the self object has been properly initialized with the required attributes. Therefore, testing this function requires initializing self with proper attributes before calling this function."
      ],
      "code_start_line": 88,
      "code_end_line": 95,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def plotLearning(self):\n        plt.plot([i for i in range(len(self.weight_list))], self.weight_list)\n        line_init = plt.axhline(y=self.initial_weight, color='r', linestyle='--')\n        line_min = plt.axhline(y=self.min_weight, color='g', linestyle='--')\n        plt.legend([line_init, line_min], ['Initial weight', 'Optimized weight'])\n        plt.ylabel('Weight')\n        plt.xlabel('Iteration')\n        plt.show()\n",
      "name_column": 8,
      "item_status": "doc_upto_date",
      "who_reference_me": [
        "TSP/tsp_vns.py/main(name_duplicate_version)"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ]
}